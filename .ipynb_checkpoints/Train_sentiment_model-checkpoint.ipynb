{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4LvN6dm7dhnN"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "import pickle\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, accuracy_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score,recall_score, precision_score, classification_report\n",
    "\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o4exHG0PdZ9L"
   },
   "source": [
    "# Training 4 different models for sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zm3x-jqQeAPE"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./datasets/clean_sent_160k_train.csv\",low_memory=False,error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "INc_oH-TdZ9S"
   },
   "source": [
    "### Drop all rows with NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "id": "6HsiXFevefUD",
    "outputId": "7c6becf2-d63f-42a0-a3a6-083619c37f92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1592046 entries, 0 to 1592045\n",
      "Data columns (total 2 columns):\n",
      "sentiment    1592046 non-null int64\n",
      "text         1592046 non-null object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 24.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.dropna(inplace=True)\n",
    "df.reset_index(drop=True,inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0APWcPMFefEg"
   },
   "source": [
    "### Split into testing and training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GQhTvPmEee1s"
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.2, random_state=1)\n",
    "x_train = train['text'].values\n",
    "x_test = test['text'].values\n",
    "y_train = train['sentiment']\n",
    "y_test = test['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "2Art-fNSemTV",
    "outputId": "e77130e8-6fd7-485e-952d-a819e348fd4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words('english')\n",
    "added = ['.',',','-',';',':','--','\\\"','(',')', '\\'s','?','n\\'t', '<', '>',\n",
    "         '``', '\\'\\'', 'I', 'i', 'a', 'A', '..', '...', 'i\\'m', 'I\\'m']\n",
    "stop_words.extend(added)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HuztlXG89wg7"
   },
   "source": [
    "## Note:\n",
    " Training the models or fitting the vectorizer may take a long time, so they have been pickled and stored as \"*.sav\" files which can be loaded using pickle again without training. The vectorizer was about 250MB, so it has been compressed and stored as \".xz\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DfeYvAdkdZ9n"
   },
   "source": [
    "### Use tfidf with trigrams to vectorize the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T07uX9zumn3s"
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words=None , max_features=100000, ngram_range=(1,3))\n",
    "train_vectors = vectorizer.fit_transform(train['text'])\n",
    "test_vectors = vectorizer.transform(test['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_GYFcpPCdZ9t"
   },
   "source": [
    "### Save or load vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a2k6UbZ9dZ9u"
   },
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "\n",
    "# Uncomment the next line to save the created vectorizer\n",
    "# filename = 'models/tfidf.xz'\n",
    "# dump(vectorizer, filename)\n",
    "\n",
    "# uncomment the next line to load the saved vectorizer\n",
    "# vectorizer = load('./models/tfidf.xz')\n",
    "# train_vectors = vectorizer.fit_transform(train['text'])\n",
    "# test_vectors = vectorizer.transform(test['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gwwv-A10dZ9x"
   },
   "source": [
    "# Training the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z8h8FQ6Rqxhd"
   },
   "source": [
    "## 1. Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "sVK4MJppmnr_",
    "outputId": "62ecba1a-569e-48f2-abbe-640fa14169ff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l1', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Linear_SVC = LinearSVC(penalty=\"l1\", dual=False)\n",
    "Linear_SVC.fit(train_vectors, train['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 184
    },
    "colab_type": "code",
    "id": "gDkVbBMYmng8",
    "outputId": "b302f59e-061b-46f5-b28e-9bff48761ec9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.77      0.79    159017\n",
      "           1       0.78      0.81      0.80    159393\n",
      "\n",
      "   micro avg       0.79      0.79      0.79    318410\n",
      "   macro avg       0.79      0.79      0.79    318410\n",
      "weighted avg       0.79      0.79      0.79    318410\n",
      "\n",
      "accuracy: 0.7915611946860965\n"
     ]
    }
   ],
   "source": [
    "prediction_linear = Linear_SVC.predict(test_vectors)\n",
    "\n",
    "\n",
    "report = classification_report(test['sentiment'], prediction_linear)\n",
    "acc_svc = accuracy_score(test['sentiment'], prediction_linear)\n",
    "\n",
    "print(report)\n",
    "print(\"accuracy:\",acc_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z4S6EWiPdZ95"
   },
   "source": [
    "### Save the model for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3olmPg6m15I7"
   },
   "outputs": [],
   "source": [
    "# filename = './models/linear_svc.sav'\n",
    "# pickle.dump(Linear_SVC, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T5WLIbH4q_E2"
   },
   "source": [
    "## 2. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "wj-TH5A9n3Ut",
    "outputId": "96dbf485-bb78-4408-c183-64dbcf64d8be"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Linear_regression = LogisticRegression()\n",
    "Linear_regression.fit(train_vectors, train['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 184
    },
    "colab_type": "code",
    "id": "XidRmhiGn3RJ",
    "outputId": "5006501a-64b6-4fd5-ae1f-1643f225bf03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.78      0.79    159017\n",
      "           1       0.79      0.81      0.80    159393\n",
      "\n",
      "   micro avg       0.80      0.80      0.80    318410\n",
      "   macro avg       0.80      0.80      0.80    318410\n",
      "weighted avg       0.80      0.80      0.80    318410\n",
      "\n",
      "accuracy: 0.7962469771678026\n"
     ]
    }
   ],
   "source": [
    "prediction_linear = Linear_regression.predict(test_vectors)\n",
    "\n",
    "\n",
    "report = classification_report(test['sentiment'], prediction_linear)\n",
    "acc_reg = accuracy_score(test['sentiment'], prediction_linear)\n",
    "print(report)\n",
    "print(\"accuracy:\", acc_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CK3smYXN2-3C"
   },
   "outputs": [],
   "source": [
    "# filename = './models/linear_regression.sav'\n",
    "# pickle.dump(Linear_regression, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sP116sxEtOmE"
   },
   "source": [
    "## 3. Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "RjS813bntOMH",
    "outputId": "a3ec9091-9ee2-4be5-d1d6-e12a72304fb4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_NB = MultinomialNB()\n",
    "classifier_NB.fit(train_vectors, train['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 184
    },
    "colab_type": "code",
    "id": "gnK_xo7tn3PG",
    "outputId": "482c9d39-b539-47d7-e2f4-f0ea8abc0d2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.78      0.78    159017\n",
      "           1       0.78      0.78      0.78    159393\n",
      "\n",
      "   micro avg       0.78      0.78      0.78    318410\n",
      "   macro avg       0.78      0.78      0.78    318410\n",
      "weighted avg       0.78      0.78      0.78    318410\n",
      "\n",
      "accuracy: 0.779246882949656\n"
     ]
    }
   ],
   "source": [
    "prediction_linear = classifier_NB.predict(test_vectors)\n",
    "\n",
    "\n",
    "report = classification_report(test['sentiment'], prediction_linear)\n",
    "acc_nb = accuracy_score(test['sentiment'], prediction_linear)\n",
    "print(report)\n",
    "print(\"accuracy:\",acc_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pgFKWjHu3FAj"
   },
   "outputs": [],
   "source": [
    "# filename = './models/multinomial_NB.sav'\n",
    "# pickle.dump(classifier_NB, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dMHP2nI-uSq4"
   },
   "source": [
    "## 4. LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "f3Ro886MvEa_",
    "outputId": "5d9e0b1a-3d66-4f21-8c9e-99834b169439"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D, Dropout\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FPmvr68u3PRn"
   },
   "source": [
    "### Reducing the number of rows, to make training time reasonable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "id": "r4oNJsi905oy",
    "outputId": "c2c40a80-5d1f-4d19-a728-5e567ca4b88b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 79603 entries, 0 to 1592040\n",
      "Data columns (total 2 columns):\n",
      "sentiment    79603 non-null int64\n",
      "text         79603 non-null object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "small_df = df[::20]\n",
    "small_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "51cVJlH4dZ-c"
   },
   "source": [
    "### Clean the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 168
    },
    "colab_type": "code",
    "id": "F7hx1YmcPNun",
    "outputId": "559361ef-6c0c-48cc-f2e0-e97c9d6a4714"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 79484 entries, 0 to 1592040\n",
      "Data columns (total 2 columns):\n",
      "sentiment    79484 non-null int64\n",
      "text         79484 non-null object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "extra_clean = []\n",
    "\n",
    "for line in small_df['text']:\n",
    "  tweet = re.sub(\"[^a-zA-Z]\", \" \", line)\n",
    "  tweet = [wordnet_lemmatizer.lemmatize(x) for x in tweet.split(\" \") if\n",
    "             x not in stop_words and len(x) > 2]\n",
    "  \n",
    "  extra_clean.append(\" \".join(tweet))\n",
    "  \n",
    "small_df['text'] = extra_clean\n",
    "small_df = small_df.drop(small_df[small_df['text'] == ''].index)\n",
    "small_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "asxamUHHdZ-h"
   },
   "source": [
    "### Get vocabulary size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "E-bzdrfpuGQ2",
    "outputId": "7caec7c9-b939-48d2-801d-10cc997c1379"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49111 530761\n"
     ]
    }
   ],
   "source": [
    "vocab = []\n",
    "for x in small_df['text']:\n",
    "    for word in x.split(' '):\n",
    "        vocab.append(word)\n",
    "print(len(set(vocab)), len(vocab))\n",
    "\n",
    "vocab_size = len(set(vocab)) +500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "M1PPHTGm15Jk",
    "outputId": "43a1d4bf-ebe8-44ed-9daf-aba725d3dd6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum review length: 125\n",
      "Minimum review length: 2\n"
     ]
    }
   ],
   "source": [
    "print('Maximum review length: {}'.format(\n",
    "len(max((small_df['text']), key=len))))\n",
    "\n",
    "print('Minimum review length: {}'.format(\n",
    "len(min((small_df['text']), key=len))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yu5dShWydZ-n"
   },
   "source": [
    "### Tokenize and pad the input sequences for the LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "46ySJfwjuGC_"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=20000)\n",
    "\n",
    "max_words = 20\n",
    "\n",
    "tokenizer.fit_on_texts(small_df['text'].values)\n",
    "X = tokenizer.texts_to_sequences(small_df['text'].values)\n",
    "X = pad_sequences(X, maxlen=max_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D-Z2PLs7dZ-s"
   },
   "source": [
    "### Create the LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "colab_type": "code",
    "id": "NhgbdGJWwuxM",
    "outputId": "27b06fbd-0176-43f6-e6ad-adaf295b67f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "embed_dim = 32\n",
    "lstm_out = 32\n",
    "batch_size= 128\n",
    "\n",
    "# #Buidling the LSTM network\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(20000, embed_dim, input_length = max_words))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(lstm_out))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss = 'binary_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IsKx033LuFzu"
   },
   "outputs": [],
   "source": [
    "Y = small_df['sentiment']\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X,Y, test_size = 0.20, random_state = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nhr-yJdf15Ju"
   },
   "outputs": [],
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "colab_type": "code",
    "id": "jgogasctwXcw",
    "outputId": "79f4f2c7-f6a4-4474-b1d3-c2192da47c10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/1\n",
      "63587/63587 [==============================] - 19s 291us/step - loss: 0.5631 - acc: 0.7062\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc5296d7c18>"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.fit(X_train, Y_train, epochs = 1, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "4wrRQOl-wXZu",
    "outputId": "4de110a2-2672-43d4-f447-d435cf9dafbe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logloss score: 0.50\n",
      "Accuracy: 0.75838\n"
     ]
    }
   ],
   "source": [
    "score,acc = model.evaluate(X_valid, Y_valid, batch_size = batch_size, verbose = 0)\n",
    "print(\"Logloss score: %.2f\" % (score))\n",
    "print(\"Accuracy: %.5f\" % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MSvHDy7dwXXY"
   },
   "outputs": [],
   "source": [
    "# filename = './models/LSTM.sav'\n",
    "# pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1MaobP1OdZ_E"
   },
   "source": [
    "### Compare the accuracy of the 4 methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "AbLWYPydAJ0Z",
    "outputId": "e06a111b-5f4c-4cfb-8fa4-79a22cd65e9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy- \n",
      "SVC: 0.792\n",
      "Linear Reg: 0.796\n",
      "Naive Bayes: 0.779\n",
      "LSTM: 0.758\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy- \")\n",
    "print(\"SVC: %.3f\" % acc_svc)\n",
    "print(\"Linear Reg: %.3f\" % acc_reg)\n",
    "print(\"Naive Bayes: %.3f\" % acc_nb)\n",
    "print(\"LSTM: %.3f\" % acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BmMIV-LZ4GkZ"
   },
   "source": [
    "# Observation\n",
    "\n",
    "### Of the 4 methods we used logistic regression gives us the best accuracy. With SVM close behind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yi8PE1OOdZ_I"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Train_sentiment_model_final.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
